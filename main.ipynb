{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corpus\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CaboCha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0 1D 0/1 1.997244\n",
      "暑く\t形容詞,自立,*,*,形容詞・アウオ段,連用テ接続,暑い,アツク,アツク\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "* 1 3D 0/1 -1.801677\n",
      "眠い\t形容詞,自立,*,*,形容詞・アウオ段,基本形,眠い,ネムイ,ネムイ\n",
      "ので\t助詞,接続助詞,*,*,*,*,ので,ノデ,ノデ\n",
      "* 2 3D 0/1 -1.801677\n",
      "今日\t名詞,副詞可能,*,*,*,*,今日,キョウ,キョー\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "* 3 -1D 0/1 0.000000\n",
      "休み\t動詞,自立,*,*,五段・マ行,連用形,休む,ヤスミ,ヤスミ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = CaboCha.Parser()\n",
    "txt = '暑くて眠いので今日は休みます。'\n",
    "#txt = 'そうしたらそのワンちゃんがなんかか喜んじゃって、で、あたしの方に走ってきて、とびついてきちゃってさ。'\n",
    "tree = c.parse(txt)\n",
    "print(tree.toString(CaboCha.FORMAT_LATTICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0 1 暑く\n",
      "1 3 0 1 眠い\n",
      "2 3 0 1 今日\n",
      "3 -1 0 1 休み\n"
     ]
    }
   ],
   "source": [
    "id = 0\n",
    "for i in range(tree.size()):\n",
    "    token = tree.token(i)\n",
    "    if(token.chunk):\n",
    "        tmp = token.chunk\n",
    "        print(id, tmp.link, tmp.head_pos, tmp.func_pos, token.surface)\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bunsetsu_list(tree):\n",
    "    result = []\n",
    "    chunkindex = 0\n",
    "    for i in range(tree.size()):\n",
    "        token = tree.token(i)\n",
    "        if(token.chunk is not None):\n",
    "            features = token.feature.split(',')\n",
    "            result.append({'lemma':features[-3], 'link':token.chunk.link, 'index':chunkindex})\n",
    "            chunkindex += 1\n",
    "    return result\n",
    "\n",
    "def search_candidate(known_word_index, blist):\n",
    "    result = set()\n",
    "    for b in blist:\n",
    "        if((b['link'] == known_word_index) or (b['index'] == blist[known_word_index]['link'])):\n",
    "            result.add(b['index'])\n",
    "    return sorted(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = corpus.Corpus(os.path.join('moddata','nucc','data001.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dict()\n",
    "with open(os.path.join('seeds', 'positive.txt')) as f:\n",
    "    for w in f.readlines():\n",
    "        sw = w.strip()\n",
    "        dic[sw] = corpus.WordDicElement(sw)\n",
    "        dic[sw].set_value(1.)\n",
    "with open(os.path.join('seeds', 'negative.txt')) as f:\n",
    "    for w in f.readlines():\n",
    "        sw = w.strip()\n",
    "        dic[sw] = corpus.WordDicElement(sw)\n",
    "        dic[sw].set_value(-1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'喜ぶ': <corpus.WordDicElement at 0x112c0f7c0>,\n",
       " '嬉しい': <corpus.WordDicElement at 0x112c0f580>,\n",
       " '楽しい': <corpus.WordDicElement at 0x112c0f8b0>,\n",
       " '美味しい': <corpus.WordDicElement at 0x112c0ff40>,\n",
       " 'きれい': <corpus.WordDicElement at 0x112c0faf0>,\n",
       " '美しい': <corpus.WordDicElement at 0x112c0f940>,\n",
       " '楽しむ': <corpus.WordDicElement at 0x112c0f850>,\n",
       " '悲しい': <corpus.WordDicElement at 0x113231c10>,\n",
       " 'さみしい': <corpus.WordDicElement at 0x112c0f4c0>,\n",
       " '辛い': <corpus.WordDicElement at 0x112c0f4f0>,\n",
       " '寂しい': <corpus.WordDicElement at 0x112c0fa90>,\n",
       " 'きたない': <corpus.WordDicElement at 0x112c0fdc0>,\n",
       " '痛い': <corpus.WordDicElement at 0x112c0f190>,\n",
       " 'まずい': <corpus.WordDicElement at 0x112c0fee0>,\n",
       " '残念': <corpus.WordDicElement at 0x1128acc70>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<corpus.WordDicElement at 0x112c0f7c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['喜ぶ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(cp, argdic):\n",
    "    dic = argdic.copy()\n",
    "    linecount = 0\n",
    "    for line in cp.conversation:\n",
    "        linecount += 1\n",
    "        print(f'  {linecount}')\n",
    "        for bindex, b in enumerate(line.bunsetsu_index_list):\n",
    "            bunsetsu_head = line.sentence_list[b]\n",
    "            try:\n",
    "                dic[bunsetsu_head.lemma].accesscount += 1\n",
    "                if(dic[bunsetsu_head.lemma].isvisited and abs(dic[bunsetsu_head.lemma].value) > 0.7):\n",
    "                    candidates = line.search_candidate(b)\n",
    "                    for candidate_index in candidates:\n",
    "                        candidate = line.sentence_list[candidate_index]\n",
    "                        try:\n",
    "                            dic[candidate.lemma].add_score(corpus.extract(dic[bunsetsu_head.lemma], dic[candidate.lemma]))\n",
    "                        except KeyError:\n",
    "                            newword = corpus.WordDicElement(candidate.lemma)\n",
    "                            newword.add_score(corpus.extract(dic[bunsetsu_head.lemma], newword))\n",
    "                            dic[candidate.lemma] = newword\n",
    "            except KeyError:\n",
    "                continue\n",
    "    return dic\n",
    "\n",
    "def calc_value(argdic, alpha=0.5):\n",
    "    dic = argdic.copy()\n",
    "    for key in dic.keys():\n",
    "        elem = dic[key]\n",
    "        if(len(elem.score) < 1):\n",
    "            continue\n",
    "        elif(elem.isvisited):\n",
    "            dic[key].set_value(sum(elem.score)/len(elem.score) * alpha + elem.value * (1-alpha))\n",
    "        else:\n",
    "            dic[key].set_value(sum(elem.score)/len(elem.score))\n",
    "        dic[key].reset_score()\n",
    "            \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef calc_score(cp, argdic):\\n    c = CaboCha.Parser()\\n    dic = argdic.copy()\\n    for line in cp.conversation:\\n        tree = c.parse(line['content'])\\n        blist = bunsetsu_list(tree)\\n        for bindex, b in enumerate(blist):\\n            try:\\n                dic[b['lemma']].accesscount += 1\\n                if(dic[b['lemma']].isvisited and abs(dic[b['lemma']].value) > 0.7):\\n                    candidates = search_candidate(bindex, blist)\\n                    for candidate_index in candidates:\\n                        candidate = blist[candidate_index]\\n                        try:\\n                            dic[candidate['lemma']].add_score(corpus.extract(dic[b['lemma']], dic[candidate['lemma']]))\\n                        except KeyError:\\n                            newword = corpus.WordDicElement(candidate.lemma)\\n                            newword.add_score(corpus.extract(dic[b['lemma']], newword))\\n                            dic[candidate['lemma']] = newword\\n            except KeyError:\\n                continue\\n    return dic\\n\\ndef calc_value(argdic, alpha=0.5):\\n    dic = argdic.copy()\\n    for key in dic.keys():\\n        elem = dic[key]\\n        if(len(elem.score) < 1):\\n            continue\\n        elif(elem.isvisited):\\n            dic[key].set_value(sum(elem.score)/len(elem.score) * alpha + elem.value * (1-alpha))\\n        else:\\n            dic[key].set_value(sum(elem.score)/len(elem.score))\\n        dic[key].reset_score()\\n            \\n    return dic\\n        \\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#旧版\n",
    "'''\n",
    "def calc_score(cp, argdic):\n",
    "    c = CaboCha.Parser()\n",
    "    dic = argdic.copy()\n",
    "    for line in cp.conversation:\n",
    "        tree = c.parse(line['content'])\n",
    "        blist = bunsetsu_list(tree)\n",
    "        for bindex, b in enumerate(blist):\n",
    "            try:\n",
    "                dic[b['lemma']].accesscount += 1\n",
    "                if(dic[b['lemma']].isvisited and abs(dic[b['lemma']].value) > 0.7):\n",
    "                    candidates = search_candidate(bindex, blist)\n",
    "                    for candidate_index in candidates:\n",
    "                        candidate = blist[candidate_index]\n",
    "                        try:\n",
    "                            dic[candidate['lemma']].add_score(corpus.extract(dic[b['lemma']], dic[candidate['lemma']]))\n",
    "                        except KeyError:\n",
    "                            newword = corpus.WordDicElement(candidate.lemma)\n",
    "                            newword.add_score(corpus.extract(dic[b['lemma']], newword))\n",
    "                            dic[candidate['lemma']] = newword\n",
    "            except KeyError:\n",
    "                continue\n",
    "    return dic\n",
    "\n",
    "def calc_value(argdic, alpha=0.5):\n",
    "    dic = argdic.copy()\n",
    "    for key in dic.keys():\n",
    "        elem = dic[key]\n",
    "        if(len(elem.score) < 1):\n",
    "            continue\n",
    "        elif(elem.isvisited):\n",
    "            dic[key].set_value(sum(elem.score)/len(elem.score) * alpha + elem.value * (1-alpha))\n",
    "        else:\n",
    "            dic[key].set_value(sum(elem.score)/len(elem.score))\n",
    "        dic[key].reset_score()\n",
    "            \n",
    "    return dic\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(filecount)\n\u001b[1;32m      5\u001b[0m     cp \u001b[38;5;241m=\u001b[39m corpus\u001b[38;5;241m.\u001b[39mCorpus(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmoddata\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnucc\u001b[39m\u001b[38;5;124m'\u001b[39m,file))\n\u001b[0;32m----> 6\u001b[0m     dic \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m dic \u001b[38;5;241m=\u001b[39m calc_value(dic)\n",
      "Cell \u001b[0;32mIn [10], line 6\u001b[0m, in \u001b[0;36mcalc_score\u001b[0;34m(cp, argdic)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m cp\u001b[38;5;241m.\u001b[39mconversation:\n\u001b[1;32m      5\u001b[0m     linecount \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m  \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlinecount\u001b[49m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m bindex, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(line\u001b[38;5;241m.\u001b[39mbunsetsu_index_list):\n\u001b[1;32m      8\u001b[0m         bunsetsu_head \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msentence_list[b]\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "filecount = 0\n",
    "for file in sorted(os.listdir(os.path.join('moddata','nucc'))):    \n",
    "    filecount += 1\n",
    "    print(filecount)\n",
    "    cp = corpus.Corpus(os.path.join('moddata','nucc',file))\n",
    "    dic = calc_score(cp, dic)\n",
    "dic = calc_value(dic)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in dic.keys():\n",
    "    if(-0.6 < dic[i].value < 0.6 or dic[i].accesscount > 1000):\n",
    "        dic[i].set_value(0.)\n",
    "        dic[i].deactivate()\n",
    "        continue\n",
    "    output.append(str(dic[i]))\n",
    "with open('outputclassed.txt', mode='w') as f:\n",
    "    f.write('\\n'.join(sorted(output, key=lambda x: int(x.split('(')[-1].replace(')','')), reverse=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a0fd0f0d99e5d6864c7c7afe1c6989aa5d650cea056a3048f58a96658917535"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
